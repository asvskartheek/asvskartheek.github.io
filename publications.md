---
layout: default
is_publications: true
---
## List of Publications

2. **Kartheek Akella**, Sai Himal Allu, Sridhar Suresh Ragupathi, Aman Singhal, Zeeshan Khan, C.V. Jawahar and Vinay P. Namboodiri
. Exploring Pair-Wise NMT for Indian Languages. *Accepted at ICON (International Conference on Natural Language Processing) 2020, Patna, India* <a href="#exploring_pairwise">[Detailed]</a>

1. Sai Praveen Kadiyala, **Kartheek Akella**, Truong Huu Tram. Program Behavior Analysis and Clustering using Performance Counters. *Accepted at DYNAMICS (DYnamic and Novel Advances in Machine Learning and Intelligent Cyber Security) part of ACSAC 2020, Austin, Texas*

**1 Paper is under peer review**

## Detailed Publications
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" style="border-style: none ">


<tbody id="exploring_pairwise">
	<tr>
		<td width="35%"><img src="/images/exploring_pairwise.jpg" width="250" style="border-style: none"></td>
		<td width="65%" valign="top">
			<p>
				<a href="https://arxiv.org/abs/2012.05786">Exploring Pair-Wise NMT for Indian Languages</a> <br>
				<strong>Kartheek Akella</strong>,
                <a href="https://wannabeog.github.io/"> Sai Himal Allu</a>,
                <a href="">Sridhar Suresh Ragupathi</a>,
                <a href="">Aman Singhal</a>,
                <a href="">Zeeshan Khan</a>,
				<a href="https://www.cse.iitk.ac.in/users/vinaypn/">Vinay P. Namboodiri</a>,
				<a href="http://faculty.iiit.ac.in/~jawahar/">C. V. Jawahar</a> <br>
			<span style="color:#9A2617;">International Conference on Natural Language Processing (ICON) 2020</span>
				<br>
                <a href="https://arxiv.org/abs/2012.05786">[arXiv]</a>
                <a href="https://github.com/asvskartheek/fairseq-working">[Code]</a>
				<br><br>
<div style="height:80px;width:500px;overflow:auto;background-color:#def;scrollbar-base-color:gold;font-family:sans-serif;font-size:10px;padding:10px;overflow:auto;border:1px solid #abf;"><strong>Abstract</strong><br>
In this paper, we address the task of improving pair-wise machine translation for specific low resource Indian languages. Multilingual NMT models have demonstrated a reasonable amount of effectiveness on resource-poor languages. In this work, we show that the performance of these models can be significantly improved upon by using back-translation through a filtered back-translation process and subsequent fine-tuning on the limited pair-wise language corpora. The analysis in this paper suggests that this method can significantly improve a multilingual model's performance over its baseline, yielding state-of-the-art results for various Indian languages.

</div>
			</p>
		</td>
		
	</tr>		
</tbody>


</table>